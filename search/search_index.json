{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p> Unopinionated contract-based verification for AI agents. </p> <p> </p>"},{"location":"#the-problem","title":"The Problem","text":"<p>Typical deterministic software uses tools like unit tests to ensure the code functions correctly. However, as we find ourselves becoming more reliant on AI agents to do our work, we will need a smarter and more efficient means of verifying their output is correct. To fix this, this library introduces a mental model known as the Agentic Contract Framework.</p> <p>Its primary function is to produce a contract with a set of commitments before the agents execution (this contract can be hardcoded, or be dynamically generated by the agent itself). Each commitment on a contract has an attached verifier, and this verifier can be set by you, the developer. If you deem a commitment can be deterministically verified, you are welcome to create a function for that (like a unit test). Otherwise, you can rely on the default semantic verifier that uses another agent to verify the correctness of the output. All the evaluations done will be collected and synced to the observability system of your choice.</p>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from sworn import Contract, Commitment, DatadogObservability\n\n# Define the contract with commitments\nobserver = DatadogObservability()\ncontract = Contract(\n    observer=observer,\n    commitments=[\n        Commitment(\n            name=\"no_harmful_content\",\n            terms=\"The agent must not produce harmful or offensive content\"\n        ),\n        Commitment(\n            name=\"stay_on_topic\",\n            terms=\"The agent must only discuss topics related to the user's query\"\n        )\n    ]\n)\n\n# Decorate your tools\n@contract.actuator\ndef send_message(content: str) -&gt; dict:\n    return {\"status\": \"sent\", \"content\": content}\n\n# Run within an execution context\nwith contract.execution() as execution:\n    # Run your agent (any framework)...\n    send_message(\"Hello, world!\")\n\n    # Verify the execution\n    results = execution.verify()\n    print(results)\n</code></pre>"},{"location":"#progressive-hardening","title":"Progressive Hardening","text":"<p>Using this library is very much a process of continuous exploration, you observe your agents, determine their failure modes and progressively \"harden\" your rules. If you discover that your agent commonly does a certain mistake, you can simply create a commitment to not do that mistake and add a deterministic verifier to help catch it 100% of the times. I would personally recommend just starting with the default semantic verifier and understanding the failure modes of your agent in your domain first!</p>"},{"location":"#architecture","title":"Architecture","text":"<pre><code>classDiagram\n    Contract --&gt; Commitment\n    Contract --&gt; Observer\n    Contract ..&gt; Execution : creates\n    Execution --&gt; Contract\n    Commitment --&gt; Verifier\n    Commitment --&gt; SemanticVerifier\n    Observer &lt;|-- DatadogObservability\n\n    class Contract {\n        +commitments: List~Commitment~\n        +observer: Observer\n        +execution() Execution\n        +actuator(func) Callable\n        +sensor(func) Callable\n    }\n\n    class Execution {\n        +tool_calls: List~ToolCall~\n        +verify() List~VerificationResult~\n        +add_tool_call(ToolCall)\n        +format() str\n    }\n\n    class Commitment {\n        +name: str\n        +terms: str\n        +verifier: Callable\n        +semantic_sampling_rate: float\n    }\n\n    class Observer {\n        &lt;&lt;interface&gt;&gt;\n        +capture_span()\n        +submit_evaluation()\n    }\n\n    class DatadogObservability {\n        +capture_span()\n        +submit_evaluation()\n    }\n\n    class Verifier {\n        &lt;&lt;deterministic&gt;&gt;\n    }\n\n    class SemanticVerifier {\n        &lt;&lt;LLM-based&gt;&gt;\n    }\n</code></pre>"},{"location":"#key-concepts","title":"Key Concepts","text":""},{"location":"#contracts-and-commitments","title":"Contracts and Commitments","text":"<p>The main contribution of this library is the Contract class. A contract stores many commitments. Think of a commitment as an expectation of what the agent is supposed to deliver. And a contract is a set of expectations. It's like a freelancer contract, but with your AI agent.</p>"},{"location":"#verification-strategy","title":"Verification Strategy","text":"<p>You build a contract by first defining it and adding commitments to it. A commitment can hold its own verifier. My approach to this is to be as critical as possible towards the output of the AI agent. If your verifier returns a violation, then it is taken that the agent failed to deliver what it committed to. But if your verifier returns a pass, then it is taken that the agent managed to pass a deterministic test case but could potentially have other failure modes that we do not know of (after all, using this library is a process of exploration). In this case, we run it against a semantic verifier to check for these unknown failure modes.</p>"},{"location":"#sampling-rate","title":"Sampling Rate","text":"<p>If you are confident that the deterministic test case is enough to account for all failure modes, you can set semantic_sampling_rate to be 0, meaning none of the agent executions for that particular commitment will be put through semantic verification (but your deterministic verification will still run). If you are more cost-conscious, you can set this to some number between 0 and 1 (the lower the number, the lesser the semantic verification that are done and the lesser the cost). If it is 1, then the semantic verifier will always run if (1) your verifier doesn't exist or (2) your verifier returned a pass.</p>"},{"location":"#framework-agnostic-design","title":"Framework Agnostic Design","text":"<p>This library is pretty much framework agnostic, it doesn't lock you into any agentic framework (in fact, you can swap out frameworks without changing anything about the contract). There is a clear boundary set for this library and that is anything before your agent starts running, and anything after your agent finishes execution. This makes it independent of the execution. It traces tool calls during the agent runtime (outside of its boundary) by intercepting at the tool call level, meaning if your agent calls Python functions, then the library can trace it. If there are things that can't be traced (like agent's final output or reasoning), you can simply add it using execution.add_tool_call().</p>"},{"location":"#execution-context","title":"Execution Context","text":"<p>You may need to capture some context so that you can access it within your verifier. To do this you can use the add_context() method. The method only accepts a string now, but I'm planning to add support for structured data to allow deterministic verifers to adapt to different contexts.</p>"},{"location":"#contract-coverage","title":"Contract Coverage","text":"<p>Similar to how we compute coverage of tests on a codebase, it would also be interesting and useful to compute the coverage of your contracts on the agent's behaviour. Verifiers report the behaviour that they enforce and cover, and the contract finds the complement of the union of all these coverages to find out potential blindspots in your contract and behaviours that are not enforced. You can use this information to further tighten your contract by adding more commitments.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install sworn\n</code></pre> <p>Set your environment variables:</p> <pre><code># Required for the agent\nexport GEMINI_API_KEY=your_gemini_api_key\n\n# Required for Datadog observability (optional)\nexport DD_LLMOBS_ENABLED=1\nexport DD_LLMOBS_ML_APP=your_app_name\nexport DD_LLMOBS_AGENTLESS_ENABLED=1\nexport DD_SITE=us5.datadoghq.com\nexport DD_API_KEY=your_datadog_api_key\nexport DD_ENV=development\nexport DD_SERVICE=sworn\n</code></pre>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#sworn","title":"<code>sworn</code>","text":"<p>Sworn: Contract-based verification for AI agents.</p> <p>A framework for defining behavioral contracts and verifying AI agent compliance using both deterministic and semantic (LLM-based) verification. Integrates with Datadog for observability and supports progressive hardening from semantic to deterministic verifiers as failure modes are discovered.</p>"},{"location":"api/#sworn.Commitment","title":"<code>Commitment</code>  <code>dataclass</code>","text":"<p>A commitment representing a specific term in a contract.</p> Source code in <code>src/sworn/commitment.py</code> <pre><code>@dataclass\nclass Commitment:\n    \"\"\"A commitment representing a specific term in a contract.\"\"\"\n    name: str\n    terms: str\n    verifier: Callable[[Execution, str],\n                       IntermediateVerificationResult] | None = None\n    semantic_sampling_rate: float = 1.0\n    on_violation: Callable[[VerificationResult], None] | None = None\n\n    def verify(self, execution: Execution, observer: Observer | None = None) -&gt; VerificationResult:\n        \"\"\"\n            Verifies the execution against the commitment terms and takes into account the sampling rate.\n            If a deterministic verifier is provided, it is called first. If it passes and the sampling checks in,\n            the semantic verifier is called. If no deterministic verifier is provided, the semantic verifier is called\n            based on the sampling rate.\n        \"\"\"\n        sampled_in = random.random() &lt;= self.semantic_sampling_rate\n\n        if self.verifier:\n            try:\n                intermediate_result = self.verifier(execution, self.terms)\n            except Exception as e:\n                return VerificationResult(\n                    status=VerificationResultStatus.VERIFICATION_ERROR,\n                    commitment_name=self.name,\n                    actual=f\"Verifier raised an exception: {str(e)}\",\n                    expected=self.terms,\n                    context={}\n                )\n\n            deterministic_passed = intermediate_result.status == VerificationResultStatus.PASS\n            if deterministic_passed and sampled_in:\n                intermediate_result = semantic_verifier(execution, self.terms)\n\n        elif sampled_in:\n            intermediate_result = semantic_verifier(execution, self.terms)\n\n        else:\n            return VerificationResult(\n                status=VerificationResultStatus.SKIPPED,\n                commitment_name=self.name,\n                actual=\"Verification skipped due to sampling rate.\",\n                expected=\"N/A\",\n                context={}\n            )\n\n        if observer:\n            observer.submit_evaluation(\n                label=self.name,\n                value=intermediate_result.status.value,\n                reasoning=f\"\"\"\nExpected: {intermediate_result.expected}\nActual: {intermediate_result.actual}\nContext: {intermediate_result.context}\n\"\"\"\n            )\n\n        return VerificationResult(\n            status=intermediate_result.status,\n            commitment_name=self.name,\n            actual=intermediate_result.actual,\n            expected=intermediate_result.expected,\n            context=intermediate_result.context,\n            cover=intermediate_result.cover\n        )\n\n    def get_term(self) -&gt; str:\n        \"\"\"Returns the terms of the commitment.\"\"\"\n        return self.terms\n</code></pre>"},{"location":"api/#sworn.Commitment.get_term","title":"<code>get_term()</code>","text":"<p>Returns the terms of the commitment.</p> Source code in <code>src/sworn/commitment.py</code> <pre><code>def get_term(self) -&gt; str:\n    \"\"\"Returns the terms of the commitment.\"\"\"\n    return self.terms\n</code></pre>"},{"location":"api/#sworn.Commitment.verify","title":"<code>verify(execution, observer=None)</code>","text":"<p>Verifies the execution against the commitment terms and takes into account the sampling rate. If a deterministic verifier is provided, it is called first. If it passes and the sampling checks in, the semantic verifier is called. If no deterministic verifier is provided, the semantic verifier is called based on the sampling rate.</p> Source code in <code>src/sworn/commitment.py</code> <pre><code>    def verify(self, execution: Execution, observer: Observer | None = None) -&gt; VerificationResult:\n        \"\"\"\n            Verifies the execution against the commitment terms and takes into account the sampling rate.\n            If a deterministic verifier is provided, it is called first. If it passes and the sampling checks in,\n            the semantic verifier is called. If no deterministic verifier is provided, the semantic verifier is called\n            based on the sampling rate.\n        \"\"\"\n        sampled_in = random.random() &lt;= self.semantic_sampling_rate\n\n        if self.verifier:\n            try:\n                intermediate_result = self.verifier(execution, self.terms)\n            except Exception as e:\n                return VerificationResult(\n                    status=VerificationResultStatus.VERIFICATION_ERROR,\n                    commitment_name=self.name,\n                    actual=f\"Verifier raised an exception: {str(e)}\",\n                    expected=self.terms,\n                    context={}\n                )\n\n            deterministic_passed = intermediate_result.status == VerificationResultStatus.PASS\n            if deterministic_passed and sampled_in:\n                intermediate_result = semantic_verifier(execution, self.terms)\n\n        elif sampled_in:\n            intermediate_result = semantic_verifier(execution, self.terms)\n\n        else:\n            return VerificationResult(\n                status=VerificationResultStatus.SKIPPED,\n                commitment_name=self.name,\n                actual=\"Verification skipped due to sampling rate.\",\n                expected=\"N/A\",\n                context={}\n            )\n\n        if observer:\n            observer.submit_evaluation(\n                label=self.name,\n                value=intermediate_result.status.value,\n                reasoning=f\"\"\"\nExpected: {intermediate_result.expected}\nActual: {intermediate_result.actual}\nContext: {intermediate_result.context}\n\"\"\"\n            )\n\n        return VerificationResult(\n            status=intermediate_result.status,\n            commitment_name=self.name,\n            actual=intermediate_result.actual,\n            expected=intermediate_result.expected,\n            context=intermediate_result.context,\n            cover=intermediate_result.cover\n        )\n</code></pre>"},{"location":"api/#sworn.Contract","title":"<code>Contract</code>  <code>dataclass</code>","text":"<p>A contract consisting of multiple commitments.</p> Source code in <code>src/sworn/contract.py</code> <pre><code>@dataclass\nclass Contract:\n    \"\"\"A contract consisting of multiple commitments.\"\"\"\n    commitments: list[Commitment] = field(default_factory=list)\n    on_violation: Callable[[VerificationResult], None] | None = None\n    observer: Observer | None = None\n\n    def execution(self) -&gt; Execution:\n        \"\"\"Create a new execution context for this contract.\"\"\"\n        return Execution(_contract=self)\n\n    @property\n    def current_execution(self) -&gt; Execution:\n        \"\"\"Get the current execution from context (for use by decorators).\"\"\"\n        try:\n            return _context_execution.get()\n        except LookupError:\n            raise RuntimeError(\n                \"Must be inside 'with contract.execution():' block\")\n\n    def _verify(self, execution: Execution, observer: Observer | None = None) -&gt; list[VerificationResult]:\n        \"\"\"Verifies the execution against all commitments in the contract (internal).\"\"\"\n        obs = observer if observer is not None else self.observer\n        results: list[VerificationResult] = []\n\n        for commitment in self.commitments:\n            result: VerificationResult = commitment.verify(\n                execution, observer=obs)\n            results.append(result)\n\n            if result.status == VerificationResultStatus.PASS:\n                continue\n\n            if commitment.on_violation:\n                commitment.on_violation(result)\n                continue\n\n            if self.on_violation:\n                self.on_violation(result)\n\n        covered_indices: set[int] = set()\n        for result in results:\n            covered_indices.update(result.cover)\n\n        all_indices = set(range(len(execution.tool_calls)))\n        uncovered_indices = all_indices - covered_indices\n\n        covered = [execution.tool_calls[i] for i in covered_indices]\n        uncovered = [execution.tool_calls[i] for i in uncovered_indices]\n\n        if obs:\n            obs.submit_coverage(covered, uncovered)\n\n        return results\n\n    def traced(self, func: Callable[P, R], function: Literal[\"sensor\", \"actuator\"]) -&gt; Callable[P, R]:\n        \"\"\"Decorator to trace a function with the contract's commitments.\"\"\"\n\n        @wraps(func)\n        def wrapper(*args: P.args, **kwargs: P.kwargs) -&gt; R:\n            sig = inspect.signature(func)\n            bound = sig.bind(*args, **kwargs)\n            bound.apply_defaults()\n\n            named_args: dict = dict(bound.arguments)\n\n            start_time = time.time()\n            error: Exception | None = None\n            result = None\n\n            try:\n                result = func(*args, **kwargs)\n            except Exception as e:\n                error = e\n                raise\n            finally:\n                end_time = time.time()\n                self.current_execution.tool_calls.append(\n                    ToolCall(\n                        tool_name=func.__name__,\n                        function=function,\n                        args=named_args,\n                        tool_context=ToolContext(\n                            started_at=datetime.fromtimestamp(start_time),\n                            ended_at=datetime.fromtimestamp(end_time),\n                            duration_ms=(end_time - start_time) * 1000\n                        ),\n                        tool_response=result,\n                        error=error\n                    )\n                )\n\n            return result\n\n        return wrapper\n\n    def sensor(self, func: Callable[P, R]) -&gt; Callable[P, R]:\n        \"\"\"Decorator to trace a sensor function.\"\"\"\n        return self.traced(func, function=\"sensor\")\n\n    def actuator(self, func: Callable[P, R]) -&gt; Callable[P, R]:\n        \"\"\"Decorator to trace an actuator function.\"\"\"\n        return self.traced(func, function=\"actuator\")\n\n    def add_commitment(self, commitment: Commitment) -&gt; None:\n        \"\"\"Adds a commitment to the contract.\"\"\"\n        self.commitments.append(commitment)\n\n    def get_terms(self) -&gt; str:\n        \"\"\"Returns the combined terms of all commitments in the contract.\"\"\"\n        return \"\\n\".join([commitment.get_term() for commitment in self.commitments])\n</code></pre>"},{"location":"api/#sworn.Contract.current_execution","title":"<code>current_execution</code>  <code>property</code>","text":"<p>Get the current execution from context (for use by decorators).</p>"},{"location":"api/#sworn.Contract.actuator","title":"<code>actuator(func)</code>","text":"<p>Decorator to trace an actuator function.</p> Source code in <code>src/sworn/contract.py</code> <pre><code>def actuator(self, func: Callable[P, R]) -&gt; Callable[P, R]:\n    \"\"\"Decorator to trace an actuator function.\"\"\"\n    return self.traced(func, function=\"actuator\")\n</code></pre>"},{"location":"api/#sworn.Contract.add_commitment","title":"<code>add_commitment(commitment)</code>","text":"<p>Adds a commitment to the contract.</p> Source code in <code>src/sworn/contract.py</code> <pre><code>def add_commitment(self, commitment: Commitment) -&gt; None:\n    \"\"\"Adds a commitment to the contract.\"\"\"\n    self.commitments.append(commitment)\n</code></pre>"},{"location":"api/#sworn.Contract.execution","title":"<code>execution()</code>","text":"<p>Create a new execution context for this contract.</p> Source code in <code>src/sworn/contract.py</code> <pre><code>def execution(self) -&gt; Execution:\n    \"\"\"Create a new execution context for this contract.\"\"\"\n    return Execution(_contract=self)\n</code></pre>"},{"location":"api/#sworn.Contract.get_terms","title":"<code>get_terms()</code>","text":"<p>Returns the combined terms of all commitments in the contract.</p> Source code in <code>src/sworn/contract.py</code> <pre><code>def get_terms(self) -&gt; str:\n    \"\"\"Returns the combined terms of all commitments in the contract.\"\"\"\n    return \"\\n\".join([commitment.get_term() for commitment in self.commitments])\n</code></pre>"},{"location":"api/#sworn.Contract.sensor","title":"<code>sensor(func)</code>","text":"<p>Decorator to trace a sensor function.</p> Source code in <code>src/sworn/contract.py</code> <pre><code>def sensor(self, func: Callable[P, R]) -&gt; Callable[P, R]:\n    \"\"\"Decorator to trace a sensor function.\"\"\"\n    return self.traced(func, function=\"sensor\")\n</code></pre>"},{"location":"api/#sworn.Contract.traced","title":"<code>traced(func, function)</code>","text":"<p>Decorator to trace a function with the contract's commitments.</p> Source code in <code>src/sworn/contract.py</code> <pre><code>def traced(self, func: Callable[P, R], function: Literal[\"sensor\", \"actuator\"]) -&gt; Callable[P, R]:\n    \"\"\"Decorator to trace a function with the contract's commitments.\"\"\"\n\n    @wraps(func)\n    def wrapper(*args: P.args, **kwargs: P.kwargs) -&gt; R:\n        sig = inspect.signature(func)\n        bound = sig.bind(*args, **kwargs)\n        bound.apply_defaults()\n\n        named_args: dict = dict(bound.arguments)\n\n        start_time = time.time()\n        error: Exception | None = None\n        result = None\n\n        try:\n            result = func(*args, **kwargs)\n        except Exception as e:\n            error = e\n            raise\n        finally:\n            end_time = time.time()\n            self.current_execution.tool_calls.append(\n                ToolCall(\n                    tool_name=func.__name__,\n                    function=function,\n                    args=named_args,\n                    tool_context=ToolContext(\n                        started_at=datetime.fromtimestamp(start_time),\n                        ended_at=datetime.fromtimestamp(end_time),\n                        duration_ms=(end_time - start_time) * 1000\n                    ),\n                    tool_response=result,\n                    error=error\n                )\n            )\n\n        return result\n\n    return wrapper\n</code></pre>"},{"location":"api/#sworn.Execution","title":"<code>Execution</code>  <code>dataclass</code>","text":"Source code in <code>src/sworn/execution.py</code> <pre><code>@dataclass\nclass Execution:\n    _contract: \"Contract\"\n    tool_calls: list[ToolCall] = field(default_factory=list)\n    context: list[str] = field(default_factory=list)\n    _token: Token[\"Execution\"] | None = field(default=None, init=False, repr=False)\n\n    def __enter__(self) -&gt; \"Execution\":\n        self._token = _context_execution.set(self)\n        return self\n\n    def __exit__(self, exc_type: Any, exc_val: Any, exc_tb: Any) -&gt; bool:\n        if self._token is not None:\n            _context_execution.reset(self._token)\n            self._token = None\n        return False\n\n    def verify(self, observer: \"Observer | None\" = None) -&gt; list[VerificationResult]:\n        \"\"\"Verify this execution against its contract's commitments.\"\"\"\n        return self._contract._verify(self, observer)\n\n    def add_tool_call(self, tool_call: ToolCall) -&gt; None:\n        \"\"\"Manually add a tool call to this execution.\"\"\"\n        self.tool_calls.append(tool_call)\n\n    def add_context(self, context: str) -&gt; None:\n        \"\"\"Add context information to this execution.\"\"\"\n        self.context.append(context)\n\n    def format(self) -&gt; str:\n        \"\"\"Formats the execution context and tool calls for logging or display purposes.\"\"\"\n        context_str = \"\\n\".join(self.context)\n        tool_calls_str = \"\\n\".join([\n            f\"[{i}] Tool: {tc.tool_name}, Args: {tc.args}, Response: {tc.tool_response}\"\n            for i, tc in enumerate(self.tool_calls)\n        ])\n        return f\"===Context===\\n{context_str}\\n===Execution===\\n{tool_calls_str}\"\n</code></pre>"},{"location":"api/#sworn.Execution.add_context","title":"<code>add_context(context)</code>","text":"<p>Add context information to this execution.</p> Source code in <code>src/sworn/execution.py</code> <pre><code>def add_context(self, context: str) -&gt; None:\n    \"\"\"Add context information to this execution.\"\"\"\n    self.context.append(context)\n</code></pre>"},{"location":"api/#sworn.Execution.add_tool_call","title":"<code>add_tool_call(tool_call)</code>","text":"<p>Manually add a tool call to this execution.</p> Source code in <code>src/sworn/execution.py</code> <pre><code>def add_tool_call(self, tool_call: ToolCall) -&gt; None:\n    \"\"\"Manually add a tool call to this execution.\"\"\"\n    self.tool_calls.append(tool_call)\n</code></pre>"},{"location":"api/#sworn.Execution.format","title":"<code>format()</code>","text":"<p>Formats the execution context and tool calls for logging or display purposes.</p> Source code in <code>src/sworn/execution.py</code> <pre><code>def format(self) -&gt; str:\n    \"\"\"Formats the execution context and tool calls for logging or display purposes.\"\"\"\n    context_str = \"\\n\".join(self.context)\n    tool_calls_str = \"\\n\".join([\n        f\"[{i}] Tool: {tc.tool_name}, Args: {tc.args}, Response: {tc.tool_response}\"\n        for i, tc in enumerate(self.tool_calls)\n    ])\n    return f\"===Context===\\n{context_str}\\n===Execution===\\n{tool_calls_str}\"\n</code></pre>"},{"location":"api/#sworn.Execution.verify","title":"<code>verify(observer=None)</code>","text":"<p>Verify this execution against its contract's commitments.</p> Source code in <code>src/sworn/execution.py</code> <pre><code>def verify(self, observer: \"Observer | None\" = None) -&gt; list[VerificationResult]:\n    \"\"\"Verify this execution against its contract's commitments.\"\"\"\n    return self._contract._verify(self, observer)\n</code></pre>"},{"location":"api/#sworn.IntermediateVerificationResult","title":"<code>IntermediateVerificationResult</code>  <code>dataclass</code>","text":"<p>Intermediate result from a verifier before finalizing.</p> Source code in <code>src/sworn/types.py</code> <pre><code>@dataclass\nclass IntermediateVerificationResult:\n    \"\"\"Intermediate result from a verifier before finalizing.\"\"\"\n    status: VerificationResultStatus\n    actual: str\n    expected: str\n    context: Dict[str, Any] | None = None\n    cover: list[int] = field(default_factory=list)\n</code></pre>"},{"location":"api/#sworn.ToolCall","title":"<code>ToolCall</code>  <code>dataclass</code>","text":"<p>Represents a tool call made by the agent.</p> Source code in <code>src/sworn/types.py</code> <pre><code>@dataclass\nclass ToolCall:\n    \"\"\"Represents a tool call made by the agent.\"\"\"\n    tool_name: str\n    function: Literal[\"sensor\", \"actuator\"]\n    args: Dict[str, Any]\n    tool_context: ToolContext\n    tool_response: Any\n    error: Exception | None\n</code></pre>"},{"location":"api/#sworn.VerificationResult","title":"<code>VerificationResult</code>  <code>dataclass</code>","text":"<p>Final verification result after all checks.</p> Source code in <code>src/sworn/types.py</code> <pre><code>@dataclass\nclass VerificationResult:\n    \"\"\"Final verification result after all checks.\"\"\"\n    status: VerificationResultStatus\n    commitment_name: str\n    actual: str\n    expected: str\n    context: Dict[str, Any] | None = None\n    cover: list[int] = field(default_factory=list)\n</code></pre>"},{"location":"api/#sworn.VerificationResultStatus","title":"<code>VerificationResultStatus</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Enumeration of verification result statuses.</p> Source code in <code>src/sworn/types.py</code> <pre><code>class VerificationResultStatus(Enum):\n    \"\"\"Enumeration of verification result statuses.\"\"\"\n    PASS = \"pass\"\n    WARNING = \"warning\"\n    VIOLATION = \"violation\"\n    CRITICAL = \"critical\"\n    SKIPPED = \"skipped\"\n    VERIFICATION_ERROR = \"verification_error\"\n</code></pre>"}]}